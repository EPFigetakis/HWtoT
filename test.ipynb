{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af946d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from tqdm import tqdm\n",
    "\n",
    "# Go up one directory to reach the root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from data import collate_fn\n",
    "from data import HWLD\n",
    "from model import CRNN\n",
    "from data import create_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6cd1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 88 items to dataset.json\n",
      "✅ Converted to dataset.csv with 88 entries.\n"
     ]
    }
   ],
   "source": [
    "create_label.create_dataset_json(\n",
    "    image_dir=\"data/cropped\",\n",
    "    label_dir=\"data/labels\",\n",
    "    output_file='dataset.json'\n",
    ")\n",
    "\n",
    "\n",
    "create_label.convert_json_to_csv(\"dataset.json\",\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "712f3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HWLD.HandwritingLineDataset(\"dataset.csv\")\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn.ctc_collate_fn)\n",
    "\n",
    "charset = dataset.get_charset()\n",
    "num_classes = len(charset) + 1 \n",
    "\n",
    "\n",
    "model = CRNN.CRNN(img_height=32, num_classes=num_classes)\n",
    "\n",
    "sample_batch = next(iter(dataloader))\n",
    "logits = model(sample_batch[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a1b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cer(preds, targets):\n",
    "    import editdistance\n",
    "    total_dist, total_chars = 0, 0\n",
    "    for p, t in zip(preds, targets):\n",
    "        dist = editdistance.eval(p, t)\n",
    "        total_dist += dist\n",
    "        total_chars += len(t)\n",
    "    return total_dist / total_chars if total_chars > 0 else 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1681a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(logits, charset, blank=0):\n",
    "    # Greedy decode, collapse repeats and remove blanks\n",
    "    probs = logits.softmax(2)\n",
    "    pred_indices = probs.argmax(2)  # [T, B]\n",
    "    pred_indices = pred_indices.permute(1, 0)  # [B, T]\n",
    "\n",
    "    results = []\n",
    "    for seq in pred_indices:\n",
    "        prev = blank\n",
    "        text = \"\"\n",
    "        for idx in seq:\n",
    "            idx = idx.item()\n",
    "            if idx != blank and idx != prev:\n",
    "                text += charset[idx]\n",
    "            prev = idx\n",
    "        results.append(text)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f0f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, charset,num_epochs=20,lr=1e-3,device=\"cuda\" if torch.cuda.is_available() else \"cpu\",save_path=\"crnn_best.pth\"):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\n",
    "    criterion = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "\n",
    "    best_val_cer = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch in loop:\n",
    "            images = batch[\"images\"].to(device)  # [B, 1, 32, W]\n",
    "            targets = batch[\"label\"].to(device)\n",
    "            label_lengths = batch[\"label_lengths\"].to(device)\n",
    "            input_lengths = batch[\"input_lengths\"].to(device)\n",
    "            #label_lengths = torch.tensor([len(l) for l in labels], dtype=torch.long)\n",
    "\n",
    "            # Flatten labels into a 1D tensor for CTC\n",
    "            #targets = torch.cat(labels).to(device)\n",
    "\n",
    "            logits = model(images)  # [T, B, C]\n",
    "            #input_lengths = torch.full(size=(logits.size(1),), fill_value=logits.size(0), dtype=torch.long)\n",
    "\n",
    "            loss = criterion(logits.log_softmax(2), targets, input_lengths, label_lengths)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch[\"images\"].to(device)\n",
    "                labels = batch[\"label_strs\"]\n",
    "                logits = model(images)\n",
    "                decoded = decode_predictions(logits.cpu(), charset)\n",
    "                all_preds.extend(decoded)\n",
    "                all_targets.extend(labels)\n",
    "\n",
    "        val_cer = cer(all_preds, all_targets)\n",
    "        scheduler.step(val_cer)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {epoch_loss / len(train_loader):.4f}, Val CER = {val_cer:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_cer < best_val_cer:\n",
    "            best_val_cer = val_cer\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✅ Saved best model with CER = {val_cer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b28dfed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manol\\anaconda3\\envs\\SymPinn\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch: torch.Size([4, 1, 32, 838])\n",
      "Label concat: torch.Size([203])\n",
      "Label lengths: tensor([38, 54, 56, 55])\n",
      "tensor([33, 25,  1, 38, 27, 24,  1, 25, 24, 20, 38, 39, 36, 24, 37,  1, 38, 27,\n",
      "        20, 38,  1, 27, 20, 40, 24,  1, 21, 24, 24, 32,  1, 24, 32, 22, 33, 23,\n",
      "        24, 23])\n",
      "tensor([38, 27, 24,  1,  5, 27, 39, 36, 22, 27,  1, 20, 32, 23,  1, 27, 20, 37,\n",
      "         1, 38, 27, 24,  1, 34, 33, 41, 24, 36,  1, 38, 33,  1, 31, 20, 29, 24,\n",
      "         1, 21, 28, 32, 23, 28, 32, 26,  1, 23, 24, 22, 28, 37, 28, 33, 32, 37])\n",
      "tensor([22, 33, 31, 34, 36, 24, 37, 37, 28, 33, 32,  1, 20, 32, 23,  1, 36, 24,\n",
      "        23, 39, 22, 38, 28, 33, 32,  1, 38, 27, 24, 36, 24, 21, 43,  1, 24, 32,\n",
      "        27, 20, 32, 22, 28, 32, 26,  1, 38, 36, 20, 32, 37, 31, 28, 37, 37, 28,\n",
      "        33, 32])\n",
      "tensor([20, 22, 22, 39, 36, 20, 22, 43,  1, 33, 25,  1, 38, 36, 20, 32, 37, 31,\n",
      "        28, 38, 38, 24, 23,  1, 21, 28, 38, 37,  1, 17, 27, 28, 37,  1, 20, 34,\n",
      "        34, 36, 33, 20, 22, 27,  1, 28, 32, 40, 33, 30, 40, 24, 37,  1, 38, 27,\n",
      "        24])\n",
      "Label 0: tensor([33, 25,  1, 38, 27, 24,  1, 25, 24, 20, 38, 39, 36, 24, 37,  1, 38, 27,\n",
      "        20, 38,  1, 27, 20, 40, 24,  1, 21, 24, 24, 32,  1, 24, 32, 22, 33, 23,\n",
      "        24, 23]), shape: torch.Size([38])\n",
      "Label 1: tensor([38, 27, 24,  1,  5, 27, 39, 36, 22, 27,  1, 20, 32, 23,  1, 27, 20, 37,\n",
      "         1, 38, 27, 24,  1, 34, 33, 41, 24, 36,  1, 38, 33,  1, 31, 20, 29, 24,\n",
      "         1, 21, 28, 32, 23, 28, 32, 26,  1, 23, 24, 22, 28, 37, 28, 33, 32, 37]), shape: torch.Size([54])\n",
      "Label 2: tensor([22, 33, 31, 34, 36, 24, 37, 37, 28, 33, 32,  1, 20, 32, 23,  1, 36, 24,\n",
      "        23, 39, 22, 38, 28, 33, 32,  1, 38, 27, 24, 36, 24, 21, 43,  1, 24, 32,\n",
      "        27, 20, 32, 22, 28, 32, 26,  1, 38, 36, 20, 32, 37, 31, 28, 37, 37, 28,\n",
      "        33, 32]), shape: torch.Size([56])\n",
      "Label 3: tensor([20, 22, 22, 39, 36, 20, 22, 43,  1, 33, 25,  1, 38, 36, 20, 32, 37, 31,\n",
      "        28, 38, 38, 24, 23,  1, 21, 28, 38, 37,  1, 17, 27, 28, 37,  1, 20, 34,\n",
      "        34, 36, 33, 20, 22, 27,  1, 28, 32, 40, 33, 30, 40, 24, 37,  1, 38, 27,\n",
      "        24]), shape: torch.Size([55])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m     offset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m---> 43\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcharset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcharset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, charset, num_epochs, lr, device, save_path)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     41\u001b[0m     images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 42\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_str\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     43\u001b[0m     logits \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     44\u001b[0m     decoded \u001b[38;5;241m=\u001b[39m decode_predictions(logits\u001b[38;5;241m.\u001b[39mcpu(), charset)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label_str'"
     ]
    }
   ],
   "source": [
    "dataset = HWLD.HandwritingLineDataset(\"dataset.csv\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "indices = list(range(len(dataset)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "\n",
    "train_data = Subset(dataset, train_idx)\n",
    "val_data = Subset(dataset, val_idx)\n",
    "\n",
    "#train_data, val_data = random_split(dataset, [62, 26])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=collate_fn.ctc_collate_fn)\n",
    "val_loader = DataLoader(val_data, batch_size=4, shuffle=True, collate_fn=collate_fn.ctc_collate_fn)\n",
    "\n",
    "#charset = train_loader.dataset.charset\n",
    "charset = dataset.get_charset()\n",
    "num_classes = len(charset) + 1\n",
    "model = CRNN.CRNN(img_height=32, num_classes=num_classes)\n",
    "\n",
    "#sample_batch = next(iter(train_loader))\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(\"Image batch:\", batch['images'].shape)\n",
    "    print(\"Label concat:\", batch['label'].shape)\n",
    "    print(\"Label lengths:\", batch['label_lengths'])\n",
    "    \n",
    "    offset = 0\n",
    "    for l in batch['label_lengths']:\n",
    "        print(batch['label'][offset:offset + l.item()])\n",
    "        offset += l.item()\n",
    "    break\n",
    "\n",
    "labels = batch['label']\n",
    "lengths = batch['label_lengths']\n",
    "\n",
    "offset = 0\n",
    "for i, length in enumerate(lengths):\n",
    "    label = labels[offset:offset + length]\n",
    "    print(f\"Label {i}: {label}, shape: {label.shape}\")\n",
    "    offset += length\n",
    "\n",
    "train(model=model,train_loader=train_loader,val_loader=val_loader,charset=charset,num_epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SymPinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
